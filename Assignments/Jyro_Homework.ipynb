{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jyro Homework Testbed\n",
    "\n",
    "## I'm giving you the code I'll use to generate random robot worlds for your homework. \n",
    "\n",
    "### The goal of this environment it to get as close to the light source as you can within 500 steps of the simulator using an evolved controller. \n",
    "Note that trying to evolve something using 500 steps from the very begening will take a looonnnggg time (so I don't reccomend it). \n",
    "\n",
    "### You should feel free to manipulate the fitness function, selection methods, recombination, diversity maintenance, and the structure of the neural network brain to try and evolve better robots. \n",
    "\n",
    "### You may also use genetic programing to evolve a brain for this robot, in which case you'll want to also change the kinds of function nodes available to evolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from jyro.simulator import *\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Here is the main difference, I'm just random generating some walls\n",
    "#either on the left or right side of the world, evenly spaced along \n",
    "#the length of the world. \n",
    "def add_walls(sim, num_walls):\n",
    "    pos_xs = np.linspace(1.5, 10, num_walls)\n",
    "\n",
    "    for i in range(num_walls):\n",
    "        width = random.uniform(0.1, 0.3)\n",
    "        pos_y1 = random.choice([12-0.25, 0.25])\n",
    "        length = random.uniform(3, 10)\n",
    "        sim.addBox(pos_y1, pos_xs[i], length, pos_xs[i]+width, fill=\"gray\", wallcolor=\"gray\")\n",
    "\n",
    "# We'll create a box for the robot to live in\n",
    "# and a light source\n",
    "def make_world(sim):\n",
    "    sim.addBox(0, 0, 12, 12, fill=\"backgroundgreen\", wallcolor=\"gray\") #bounding box\n",
    "    sim.addLight(11, 11, 1) #paramters are x, y, brightness\n",
    "    add_walls(sim, 6)\n",
    "    \n",
    "#We'll give our robot the 16 sonar distance sensors, some light sensors\n",
    "class MyPioneer(Pioneer):\n",
    "    def __init__(self, name, x, y, angle):\n",
    "        Pioneer.__init__(self, name, x, y, angle)\n",
    "        self.addDevice(Pioneer16Sonars())\n",
    "        #parameter defines max range in meters\n",
    "        self.addDevice(PioneerFrontLightSensors(3))\n",
    "        \n",
    "    def move(self, linear, rotational):\n",
    "        if -1 > linear > 1 or -1 > rotational > 1:\n",
    "            super().move(random.uniform(-1, 1), random.uniform(-1, 1))\n",
    "            print(\"moving randomly!\")\n",
    "        else:\n",
    "            super().move(linear, rotational)\n",
    "        \n",
    "\n",
    "\n",
    "def setup_world(robot_brain):\n",
    "    robot = MyPioneer(\"Johnny\", 1, 1, 0)\n",
    "    sim = Physics()\n",
    "    make_world(sim)\n",
    "    sim.addRobot(robot)\n",
    "    robot.brain = robot_brain\n",
    "    return sim, robot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same neural network code from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNet():\n",
    "    #This is our squashing function\n",
    "    #I changed this to the hyperbolic tangent function that\n",
    "    #returns values in (-1, 1)\n",
    "    def activation_function(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    #this should look familiar, just a way to create a copy of \n",
    "    #the network without worying about pesky reference \n",
    "    def deepcopy(self):\n",
    "        new_net = SimpleNeuralNet(self.num_inputs, self.num_outputs, self.layer_node_counts)\n",
    "        new_net.layers = [np.copy(layer) for layer in self.layers]\n",
    "        return new_net\n",
    "    \n",
    "    #this is where the neural network does its computation!\n",
    "    def execute(self, input_vector):\n",
    "        # First we need to make sure we're getting the right\n",
    "        # number of inputs into our neural network.\n",
    "        assert len(input_vector) == self.num_inputs ,\\\n",
    "        \"wrong input vector size\"\n",
    "\n",
    "        # create a temporary variable to hold the values that should go\n",
    "        # into the next layer of the network.\n",
    "        # **at the start, this will just be our input**\n",
    "        next_v = input_vector\n",
    "\n",
    "        # iterate through layers, computing the activation\n",
    "        # of the weighted inputs from the previous layer\n",
    "        for layer in self.layers:\n",
    "            # add a bias to each layer [1]\n",
    "            next_v = np.append(next_v, 1)\n",
    "            \n",
    "            # pump the input vector through the matrix multiplication\n",
    "            # and our activation function\n",
    "            next_v = self.activation_function(np.dot(next_v, layer))\n",
    "            \n",
    "        return next_v\n",
    "        \n",
    "    def __init__(self, num_inputs, num_outputs, layer_node_counts=[]):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.layer_node_counts = layer_node_counts\n",
    "        self.num_outputs = num_outputs\n",
    "        self.layers = []\n",
    "        \n",
    "        last_num_neurons = self.num_inputs\n",
    "        for nc in layer_node_counts + [num_outputs]:\n",
    "            # for now, we'll just use random weights in the range [-5,5]\n",
    "            # +1 handles adding a bias node for each layer of nodes\n",
    "            self.layers.append(np.random.uniform(-5, 5, size=(last_num_neurons+1, nc)))\n",
    "            last_num_neurons = nc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you were going to use genetic programing, you'll have to change this code to generate a random GP tree instead of a random neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_to_brain(simple_net):\n",
    "    \n",
    "    #Define the brain function for jyro\n",
    "    def neural_brain(a_robot):\n",
    "        sonar_sensors = a_robot[\"sonar\"].getData()\n",
    "        light_sensors = a_robot[\"light\"].getData()\n",
    "        \n",
    "        #combine the sonar and light inputs\n",
    "        combined_input = sonar_sensors + light_sensors\n",
    "\n",
    "        network = simple_net\n",
    "\n",
    "        #run the neural network with the combined input values\n",
    "        output = network.execute(combined_input)\n",
    "        \n",
    "        #use the output of the network to move the robot\n",
    "        a_robot.move(output[0], output[1])\n",
    "\n",
    "    return neural_brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And here are the functions you'll most likely want to play with to get better evolved robots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population, fitnesses, tournament_size=3):\n",
    "    sample_pop_idxs = np.random.choice(range(len(population)), size=tournament_size)\n",
    "    tourny_winner_idx = np.argmax(np.array(fitnesses)[sample_pop_idxs])\n",
    "    winner_pop_idx = sample_pop_idxs[tourny_winner_idx]\n",
    "\n",
    "    return population[winner_pop_idx]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_network(simple_net, mutation_rate=1E-3, mutation_effect_size=2):\n",
    "    for layer_to_mut in simple_net.layers:\n",
    "        dims = layer_to_mut.shape\n",
    "        num_mutations = np.random.binomial(dims[0]*dims[1], mutation_rate)\n",
    "        for i in range(num_mutations): \n",
    "            rand_i = np.random.randint(0, dims[0])\n",
    "            rand_j = np.random.randint(0, dims[1])\n",
    "            layer_to_mut[rand_i, rand_j] += np.random.normal(scale=mutation_effect_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_neuralnet_fitness(simple_net, iterations=100):\n",
    "    this_brain = network_to_brain(simple_net)\n",
    "    sim, robot = setup_world(this_brain)\n",
    "    \n",
    "    distance_moved = 0\n",
    "    \n",
    "    #reset the robot's position\n",
    "    robot.setPose(1, 1, 0)\n",
    "    robot.reset()\n",
    "    sonar = robot[\"sonar\"].getData()\n",
    "    y_2 = robot.getPose()\n",
    "    start = math.hypot(y_2[0]-sonar[0], y_2[1] - sonar[1])\n",
    "    #iterate through the simulation\n",
    "    for i in range(iterations):        \n",
    "        #but if the robot's stuck, end early!    \n",
    "        #move the robot\n",
    "        sim.step(run_brain=True)\n",
    "    y_2 = robot.getPose()\n",
    "    end = math.hypot(y_2[0]-sonar[0], y_2[1] - sonar[1])\n",
    "    return (end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evolution(pop_size, num_generations):\n",
    "    #build our random population of neural networks\n",
    "    population = [SimpleNeuralNet(18,2,[10]) for _ in range(pop_size)]\n",
    "    evo_fitnesses = []\n",
    "\n",
    "    for i in range(num_generations):\n",
    "        #evaluate the fitnesses using 50 timesteps\n",
    "        fitnesses = [measure_neuralnet_fitness(n) for n in population]\n",
    "\n",
    "        #keep track of the mean pop fitnesses\n",
    "        evo_fitnesses.append(np.mean(fitnesses))\n",
    "\n",
    "        #print the generation and the mean fitness we just stuck on the\n",
    "        #evo_fitnesses list\n",
    "        clear_output(wait=True)\n",
    "        display(i, evo_fitnesses[-1])\n",
    "\n",
    "        #do tournament selection\n",
    "        next_pop = [tournament_selection(population, fitnesses).deepcopy() for _ in range(pop_size)]\n",
    "\n",
    "        #and mutate the new networks\n",
    "        for net in next_pop:\n",
    "            mutate_network(net, mutation_rate=0.01)\n",
    "\n",
    "        population = next_pop\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These functions will work, but are probably not going to evolve very good robots. We can run them and visualize the output though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.205078618998222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evolve \n",
    "evolved_pop = run_evolution(pop_size=20, num_generations=20)\n",
    "\n",
    "#let's visualize the first individual in the population\n",
    "#Note there is no reason to expect this is the best individual!\n",
    "sim, robot = setup_world(network_to_brain(evolved_pop[0]))\n",
    "canvas = Canvas((250, 250))\n",
    "\n",
    "for i in range(500):\n",
    "    sim.step(run_brain=True)\n",
    "    sim.draw(canvas)\n",
    "    clear_output(wait=True)\n",
    "    display(canvas)\n",
    "    time.sleep(.085)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To save your robot brain, we'll use the python `pickle` module. \n",
    "## This lets us pass a copy of our brain, and an opened file to save the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#copy the network when we pickle it\n",
    "fittest = sorted(evolved_pop, key = lambda x:(measure_neuralnet_fitness(x)))\n",
    "pickle.dump(fittest[0].deepcopy(), open('my_robot_brain.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, we can use `pickle.load` to read the file, and reconstruct the network object we need to control the robot! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.SimpleNeuralNet object at 0x11381abe0>\n"
     ]
    }
   ],
   "source": [
    "loaded_brain = pickle.load(open('my_robot_brain.pkl', 'rb'))\n",
    "print(loaded_brain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now we can put that loaded in brain into a robot and run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"250\" version=\"1.1\" width=\"250\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><rect fill=\"#eef3dd\" height=\"250.0\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"250.0\" x=\"0.0\" y=\"0.0\" /><rect fill=\"#bebebe\" height=\"4.306186204825792\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"71.98856872587652\" x=\"172.80309794079014\" y=\"214.4438137951742\" /><rect fill=\"#bebebe\" height=\"5.420758592498942\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"138.15819172693546\" x=\"106.63347493973119\" y=\"177.9125747408344\" /><rect fill=\"#bebebe\" height=\"5.952400670150752\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"199.52550815361298\" x=\"5.208333333333333\" y=\"141.9642659965159\" /><rect fill=\"#bebebe\" height=\"5.197931611329054\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"170.81567023398523\" x=\"73.97599643268143\" y=\"107.30206838867095\" /><rect fill=\"#bebebe\" height=\"2.5528523275462476\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"126.6445947675167\" x=\"118.14707189914996\" y=\"74.53048100578707\" /><rect fill=\"#bebebe\" height=\"5.043182398832357\" stroke=\"#bebebe\" stroke-width=\"1\" width=\"107.64297784143673\" x=\"137.14868882522993\" y=\"36.62348426783431\" /><circle cx=\"229.16666666666666\" cy=\"20.833333333333332\" fill=\"#ffff00\" r=\"5.208333333333333\" stroke=\"#ffff00\" stroke-width=\"1\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"16.99060484957415\" x2=\"0.0\" y1=\"242.78952288530115\" y2=\"248.145425\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"17.048903705606996\" x2=\"0.0\" y1=\"241.2420718471072\" y2=\"238.9964125\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"17.655781729498287\" x2=\"0.0\" y1=\"240.39545002565313\" y2=\"229.14586458333332\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"18.691367022466622\" x2=\"0.0\" y1=\"239.52290749826616\" y2=\"210.17913124999998\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"20.6783180464376\" x2=\"16.711974271047712\" y1=\"238.89656621260914\" y2=\"147.91666666666666\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"22.027073982234434\" x2=\"59.769211189793474\" y1=\"239.0174991972077\" y2=\"147.91666666666666\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"23.00975677751993\" x2=\"122.81899454230879\" y1=\"239.3630479901362\" y2=\"147.91666666666666\" /><line fill=\"#800080\" stroke=\"#d3d3d3\" stroke-width=\"1\" x1=\"23.944933433472574\" x2=\"182.9010153511507\" y1=\"240.5973283855016\" y2=\"190.4900255329416\" /><line fill=\"#800080\" stroke=\"#d3d3d3\" stroke-width=\"1\" x1=\"25.197616004786575\" x2=\"184.15369792246472\" y1=\"244.5712304334436\" y2=\"194.4639275808835\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"25.13931714875373\" x2=\"54.6060566490483\" y1=\"246.11868147163753\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"24.532439124862442\" x2=\"29.295276112056968\" y1=\"246.9653032930916\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"23.4968538318941\" x2=\"24.87410058843899\" y1=\"247.83784582047855\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"21.509902807923126\" x2=\"21.576857082278035\" y1=\"248.46418710613554\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"20.16114687212629\" x2=\"19.474772982020088\" y1=\"248.343254121537\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"19.1784640768408\" x2=\"16.993058699540583\" y1=\"247.99770532860853\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#add8e6\" stroke-width=\"1\" x1=\"18.243287420888155\" x2=\"7.975851869428822\" y1=\"246.7634249332431\" y2=\"250.0\" /><line fill=\"#800080\" stroke=\"#a020f0\" stroke-width=\"1\" x1=\"229.16666666666666\" x2=\"213.84513788177557\" y1=\"20.833333333333332\" y2=\"36.62348333333332\" /><line fill=\"#800080\" stroke=\"#a020f0\" stroke-width=\"1\" x1=\"229.16666666666666\" x2=\"214.19593800299967\" y1=\"20.833333333333332\" y2=\"36.62348333333332\" /><polygon fill=\"white\" points=\"18.09528171527533,239.71080988396326 16.67743420674565,241.79604737331564 18.556458063716654,247.75690044522855 20.913817500731835,248.65208949183267 24.0929391390854,247.64994343478148 25.510786647615074,245.56470594542907 23.63176279064407,239.60385287351613 21.274403353628895,238.70866382691204\" stroke=\"black\" stroke-width=\"1\" /><polygon points=\"-1.0416666666666667,-1.0416666666666667 0,0 1.0416666666666667,-1.0416666666666667 0,1.0416666666666667\" stroke=\"black\" stroke-width=\"1\" transform=\"translate(21.094110427180365,243.68037665937234) rotate(162.50372363404415)\" /><circle cx=\"16.207678242502904\" cy=\"240.3058341053374\" fill=\"yellow\" r=\"0.5208333333333334\" stroke=\"orange\" stroke-width=\"1\" /><circle cx=\"23.16200682640132\" cy=\"238.1136396055379\" fill=\"yellow\" r=\"0.5208333333333334\" stroke=\"orange\" stroke-width=\"1\" /></svg>"
      ],
      "text/plain": [
       "<jyro.simulator.canvas.Canvas at 0x1192ce9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "sim, robot = setup_world(network_to_brain(loaded_brain))\n",
    "canvas = Canvas((250, 250))\n",
    "\n",
    "for i in range(500):\n",
    "    sim.step(run_brain=True)\n",
    "    sim.draw(canvas)\n",
    "    clear_output(wait=True)\n",
    "    display(canvas)\n",
    "    print(robot[\"light\"].getData())\n",
    "    time.sleep(0.01)\n",
    "    if robot.stall:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework!\n",
    "## You should turn in a pickled robot brain, and a jupyter notebook that unpickles and runs your robot (just like the above code cell). That way, I know I have the right version of whatever required classes make up your brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
